\section{Introduction}
Software defined networking is already mainstream. Newer protocols and innovative packet
processing functionalities imply that
newer packet processing pipelines are getting developed over time. Manually
optimizing such packet processing pipelines requires highly-skilled programmers, is tedious
and time-consuming, and can be repetitive.
For example, the RouteBricks paper \cite{dobrescu2009routebricks} discusses several insightful optimizations
for a simple packet-forwarding application on a modern multi-core machine; doing such careful
research for each separate (and potentially much more complex) packet processing pipeline
seems impractical. Further, these optimizations need to be re-tuned for every different
architecture.

Domain specific languages like P4\cite{Bosshart:2014:PPP:2656877.2656890} and Click\cite{kohler2000click}, are intended
to bridge this gap, by allowing manual specification of functionality using high-level constructs. In this way, several
low-level details are abstracted away from the programmer. However, the onus of efficiently mapping this high-level
specification to the underlying machine architecture, shifts to the compiler. The difference between an unoptimized
and optimized implementation for the same high-level specification can be significant.
For example, Kim et. al. \cite{Kim:2012:PBC:2349896.2349910} optimize the specification of
an IPv4 forwarding engine, specified using the Click programming model, to achieve 28 Gbps of IPv4 throughput for minimum-sized
packets
on a machine with two quad-core Intel Xeon X5550 CPUs, i.e., they achieve roughly 3.5 Gbps per CPU core for this workload.
Similarly, P4C \cite{Laki:2016:HSP:2934872.2959080}, a prototype compiler for P4,
is able to achieve 5.17 Gbps IPv4 throughput per CPU core for an identical workload configuration, on an Intel Xeon E5-2630
CPU. In contrast, a hand optimized implementation for this workload can achieve over 10Gbps per core on an
identical machine. An ideal compiler should be able to
bridge this performance gap between compiler-generated code and hand-optimized code.

We evaluate two important compiler optimizations in this context, and evaluate their performance
effects on common packet-processing workloads running on a commodity server machine: (1) efficiently exploiting
the DMA bandwidth between NIC and main memory; and (2) efficiently exploiting the memory-level
parallelism between CPU and main memory. For the latter, we also evaluate prefetching to minimize
cache-miss stalls. Finally, we rely on existing C compilers (e.g., gcc) to automatically optimize
the generated code to efficiently utilize the CPU processor (e.g., by maximizing SIMD
and instruction-level parallelism ILP). We experiment with several code configurations involving varying
degrees of available parallelism to DMA channels, and to CPU-memory channels. We show
improvements over previously published performance results for similar programs and develop a model
for reasoning about performance in this setting. We have integrated our model into the
P4C compiler, to enable it to
automatically optimize the example programs discussed in this paper.
